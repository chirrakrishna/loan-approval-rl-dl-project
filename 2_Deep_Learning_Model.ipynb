{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4461ebe4-7412-48b5-9b87-c1c237383159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f67ead-3ff4-4421-b001-6688502e3303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KRISHNA\\AppData\\Local\\Temp\\ipykernel_20640\\1919088577.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"sample_200k.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 150) (200000,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sample_200k.csv\")\n",
    "\n",
    "df['target'] = df['loan_status'].apply(\n",
    "    lambda x: 1 if str(x) in [\"Charged Off\", \"Default\"] else 0\n",
    ")\n",
    "\n",
    "X = df.drop(columns=['loan_status', 'target'], errors='ignore')\n",
    "y = df['target']\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64abd8b1-3e79-4fe1-b3d5-366da862e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (160000, 150) Test: (40000, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9429c530-abbe-422b-95de-cda25aefc8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Train: (160000, 148)\n",
      "Transformed Test : (40000, 148)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = joblib.load(\"final_preprocessor.pkl\")\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "X_train_prep = preprocessor.transform(X_train)\n",
    "X_test_prep  = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Transformed Train:\", X_train_prep.shape)\n",
    "print(\"Transformed Test :\", X_test_prep.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a9c4d0-8c4e-48db-9344-122c84a5c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dense = X_train_prep\n",
    "X_test_dense  = X_test_prep\n",
    "\n",
    "X_train_t = torch.tensor(X_train_dense, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "X_test_t = torch.tensor(X_test_dense, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1c76e1-c9fd-48f1-8cd4-710d2669b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 148\n"
     ]
    }
   ],
   "source": [
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_ds, batch_size=512, shuffle=True)\n",
    "\n",
    "input_size = X_train_t.shape[1]\n",
    "print(\"Input size:\", input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b234770a-538f-433e-a4ed-d3f48a1ea5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e66a45c-1590-4868-9d36-45aa0de74207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ready!\n"
     ]
    }
   ],
   "source": [
    "model = MLP(input_size)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "print(\"Model Ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e292b8d-b13c-4437-bd1c-c6b23a2a869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 129.8229\n",
      "Epoch 2/20 - Loss: 119.5947\n",
      "Epoch 3/20 - Loss: 119.0577\n",
      "Epoch 4/20 - Loss: 119.0054\n",
      "Epoch 5/20 - Loss: 118.8053\n",
      "Epoch 6/20 - Loss: 118.7379\n",
      "Epoch 7/20 - Loss: 118.4502\n",
      "Epoch 8/20 - Loss: 118.2425\n",
      "Epoch 9/20 - Loss: 112.2412\n",
      "Epoch 10/20 - Loss: 89.8083\n",
      "Epoch 11/20 - Loss: 70.5885\n",
      "Epoch 12/20 - Loss: 58.3951\n",
      "Epoch 13/20 - Loss: 48.9651\n",
      "Epoch 14/20 - Loss: 43.5657\n",
      "Epoch 15/20 - Loss: 43.6122\n",
      "Epoch 16/20 - Loss: 42.2416\n",
      "Epoch 17/20 - Loss: 40.2058\n",
      "Epoch 18/20 - Loss: 37.6605\n",
      "Epoch 19/20 - Loss: 36.2833\n",
      "Epoch 20/20 - Loss: 34.8856\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb).squeeze()\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ba17265-aae1-4c17-9c74-49c6c18b727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9927463064658267\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_t).squeeze()\n",
    "    test_preds = torch.sigmoid(logits).numpy()\n",
    "\n",
    "auc = roc_auc_score(y_test, test_preds)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28165978-4037-4d73-8dfd-3f6a36c776da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.04\n",
      "Best F1: 0.9458286145715364\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_t = 0\n",
    "\n",
    "for t in np.arange(0.01, 0.99, 0.01):\n",
    "    pred_labels = (test_preds >= t).astype(int)\n",
    "    f1 = f1_score(y_test, pred_labels)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_t = t\n",
    "\n",
    "print(\"Best Threshold:\", best_t)\n",
    "print(\"Best F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60ee17ac-0484-4fda-981c-3ce647d68dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved: final_dl_model.pth, dl_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"final_dl_model.pth\")\n",
    "\n",
    "# Save predictions\n",
    "df_preds = pd.DataFrame({\n",
    "    \"prob_default\": test_preds,\n",
    "    \"true_label\": y_test.values\n",
    "})\n",
    "df_preds.to_csv(\"dl_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Files saved: final_dl_model.pth, dl_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db1b2b-8584-4174-b74b-8fea1af21b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
